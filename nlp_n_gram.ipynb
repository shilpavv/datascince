{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_n_gram.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shilpavv/datascince/blob/master/nlp_n_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UFeG4SjgXarU",
        "outputId": "d49fe84d-e49f-4cb7-8ef1-6286d247cfaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re, pprint, string\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation = string.punctuation +'“'+'”'+'-'+'’'+'‘'+'—'\n",
        "string.punctuation = string.punctuation.replace('.', '')"
      ],
      "metadata": {
        "id": "eHy4jNo4YLAG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.read_csv('/content/data.csv')\n",
        "print(corpus)\n",
        "file_nl_removed = \"\"\n",
        "for line in corpus:\n",
        "  line_nl_removed = line.replace(\"\\n\", \" \")      #removes newlines\n",
        "  file_nl_removed += line_nl_removed\n",
        "file_p = \"\".join([char for char in file_nl_removed if char not in string.punctuation])   #removes all special characters\n",
        "\n",
        "print(file_p)"
      ],
      "metadata": {
        "id": "bsocShRCZfc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c6a2b1-e74a-4265-ecd5-deab67edffd1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Duration  Pulse  Maxpulse  Calories\n",
            "0          60    110       130     409.1\n",
            "1          60    117       145     479.0\n",
            "2          60    103       135     340.0\n",
            "3          45    109       175     282.4\n",
            "4          45    117       148     406.0\n",
            "..        ...    ...       ...       ...\n",
            "164        60    105       140     290.8\n",
            "165        60    110       145     300.0\n",
            "166        60    115       145     310.2\n",
            "167        75    120       150     320.4\n",
            "168        75    125       150     330.4\n",
            "\n",
            "[169 rows x 4 columns]\n",
            "DurationPulseMaxpulseCalories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents = nltk.sent_tokenize(file_p)\n",
        "print(sents)\n",
        "print(\"The number of sentences is\", len(sents)) \n",
        "#prints the number of sentences\n",
        "\n",
        "words = nltk.word_tokenize(file_p)\n",
        "print(words)\n",
        "print(\"The number of tokens is\", len(words)) \n",
        "#prints the number of tokens\n",
        "\n",
        "average_tokens = round(len(words)/len(sents))\n",
        "print(\"The average number of tokens per sentence is\",average_tokens) \n",
        "#prints the average number of tokens per sentence\n",
        "\n",
        "unique_tokens = set(words)\n",
        "print(\"The number of unique tokens are\", len(unique_tokens)) \n",
        "#prints the number of unique tokens"
      ],
      "metadata": {
        "id": "a0HBoMosalOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8353e05-1aa7-4568-cb51-d8ad52139d31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DurationPulseMaxpulseCalories']\n",
            "The number of sentences is 1\n",
            "['DurationPulseMaxpulseCalories']\n",
            "The number of tokens is 1\n",
            "The average number of tokens per sentence is 1\n",
            "The number of unique tokens are 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram=[]\n",
        "bigram=[]\n",
        "trigram=[]\n",
        "fourgram=[]\n",
        "tokenized_txt = []\n",
        "for sentence in sents:\n",
        "    sentence = sentence.lower()\n",
        "    sequence = word_tokenize(sentence) \n",
        "    for word in sequence:\n",
        "        if (word =='.'):\n",
        "            sequence.remove(word) \n",
        "        else:\n",
        "            unigram.append(word)\n",
        "    tokenized_txt.append(sequence) \n",
        "    bigram.extend(list(ngrams(sequence, 2)))  \n",
        "#unigram, bigram, trigram, and fourgram models are created\n",
        "    trigram.extend(list(ngrams(sequence, 1)))\n",
        "    fourgram.extend(list(ngrams(sequence, 2)))"
      ],
      "metadata": {
        "id": "DgEPZCH-jQ0a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removal(x):     \n",
        "#removes ngrams containing only stopwords\n",
        "    y = []\n",
        "    for pair in x:\n",
        "        count = 0\n",
        "        for word in pair:\n",
        "            if word in stop_words:\n",
        "                count = count or 0\n",
        "            else:\n",
        "                count = count or 1\n",
        "        if (count==1):\n",
        "            y.append(pair)\n",
        "    return(y)"
      ],
      "metadata": {
        "id": "-XocgY4jje0C"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = removal(bigram)\n",
        "trigram = removal(trigram)             \n",
        "fourgram = removal(fourgram)\n",
        "freq_bi = nltk.FreqDist(bigram)\n",
        "freq_tri = nltk.FreqDist(trigram)\n",
        "freq_four = nltk.FreqDist(fourgram)\n",
        "print(\"Most common n-grams without stopword removal and without add-1 smoothing: \\n\")\n",
        "print (\"Most common bigrams: \", freq_bi.most_common(5))\n",
        "print (\"\\nMost common trigrams: \", freq_tri.most_common(5))\n",
        "print (\"\\nMost common fourgrams: \", freq_four.most_common(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8pkjJvgjiq1",
        "outputId": "468c78d3-a2f1-4665-fa31-8f72de215260"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common n-grams without stopword removal and without add-1 smoothing: \n",
            "\n",
            "Most common bigrams:  []\n",
            "\n",
            "Most common trigrams:  [(('durationpulsemaxpulsecalories',), 1)]\n",
            "\n",
            "Most common fourgrams:  []\n"
          ]
        }
      ]
    }
  ]
}